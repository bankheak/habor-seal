plot(pnorm(x,10,1))
x<-c(50:250)
plot(punif(x,100,210))
data<-c(456, 360, 612, 500, 587, 493,518)
mean(data)
median(data)
har.mean <- function(x){
length(x)/sum(1/x)
}
har.mean(data)
var(data)
quantile(data)
se <- function(x) sd(x)/sqrt(length(x))
se(data)
snow.data<-data.frame(Altitude=c(1234,1457,1637,1893,2011,2108,2383),Species.rich=c(4,5,9,5,7,18,4))
cor.test(snow.data$Altitude,snow.data$Species.rich)
cov(snow.data)
sd(snow.data$Altitude)
sd(snow.data$Species.rich)
crab <- iidspace(c("No Crab", "Crab"), ntrials = 80, probs = c(0.82, 0.18))
require(prob)
crab <- iidspace(c("No Crab", "Crab"), ntrials = 80, probs = c(0.82, 0.18))
require("prob")
crab <- iidspace(c("No Crab", "Crab"), ntrials = 80, probs = c(0.82, 0.18))
crab <- iidspace(c("No Crab", "Crab"), probs = c(0.82, 0.18))
crab <- iidspace(c("No Crab", "Crab"), ntrials = 10, probs = c(0.82, 0.18))
n<-80
x<-0:80
y<-pbinom(x,size=n,prob = 0.18)
plot(x,y)
pbinom(x,20,0.18)
dbinom(20,80,0.18)
pbinom(32,80,0.18)
1-pbinom(18,80,0.18)
pnorm(4,15,10)
1-pchisq(18,4)
ppois(18,8)-ppois(4,8)
ppois(4,8)-ppois(18,8)
1-punif(18,0,34.6)
pchisq(5.6088,1)
1-pchisq(5.6088,1)
ox.data<-data.frame(High=c(12.2,8.4,12,17.9,7.3),Med=c(26.4,21.7,6.0,16.2,18.0),Low=c(17.5,9.1,18.1,28.7,4.0))
View(ox.data)
summary(ox.data)
ox.data<-data.frame(Level=c("High","Med","Low"),Ox.con=c(High=c(12.2,8.4,12,17.9,7.3),Med=c(26.4,21.7,6.0,16.2,18.0),Low=c(17.5,9.1,18.1,28.7,4.0)))
fit_lm<-lm(Ox.con~Level,data=ox.data)
anova(fit_lm)
oxy.data<-read.csv(Book1)
oxy.data<-read.csv("Book1")
library(readr)
Book1 <- read_csv("Homework/Book1.csv")
View(Book1)
View(ox.data)
ox.data<-data.frame(Ox.con=c(High=c(12.2,8.4,12,17.9,7.3),Med=c(26.4,21.7,6.0,16.2,18.0),Low=c(17.5,9.1,18.1,28.7,4.0)))
ox.data<-data.frame(High=c(12.2,8.4,12,17.9,7.3),Med=c(26.4,21.7,6.0,16.2,18.0),Low=c(17.5,9.1,18.1,28.7,4.0))
str(ox.data)
ox.data<-data.frame(Level=c("High","Med","Low"),High=c(12.2,8.4,12,17.9,7.3),Med=c(26.4,21.7,6.0,16.2,18.0),Low=c(17.5,9.1,18.1,28.7,4.0))
1-pchisq(0.5143,1)
1-ppois(6,4)
dpois(2,4)
ppois(7,4)
s1<-c(40, 82, 45, 68, 42, 36, 64, 89, 71, 68)
s2<-c(23, 41, 34, 76, 32, 56, 63, 49, 51, 44)
(twoSampleData <- data.frame(Sample1 = s1, Sample2 = s2))
mean1 <- mean(twoSampleData$Sample1)
mean2 <- mean(twoSampleData$Sample2)
pooledVar <- (sum((twoSampleData$Sample1-mean1)^2) + sum((twoSampleData$Sample2-mean2)^2))/(length(twoSampleData$Sample1) + length(twoSampleData$Sample2) - 2)
pooledSE <- sqrt(pooledVar/length(twoSampleData$Sample1) + pooledVar/length(twoSampleData$Sample2))
(tTwoSample <- (mean1 - mean2)/pooledSE)
1-pt(1.768,18)
2*pt(12.3,4)
1-pt(2.3,18)
1-pf(2,18,4)
sample<-rep(c("High","Med","Low"),each=5)
ox.data<-c(12.2,8.4,12,17.9,7.3,26.4,21.7,6.0,16.2,18.0,17.5,9.1,18.1,28.7,4.0)
(threeSampleData<-data.frame(Sample=sample,Data=ox.data))
fit_lm<-lm(ox.data~sample,data=threeSampleData)
anova(fit_lm)
plot(ox.data~sample,data=threeSampleData)
boxplot(ox.data~sample,data=threeSampleData)
boxplot(ox.data~sample,data=threeSampleData)
alc.data<-data.frame(Predictor=c(10,20,30,40,50,60),Response=c(-1.7447,-1.824,-1.7696,-1.553,-1.377,-1.194))
fit<-lm(Response~Predictor,data=alc.data)
summary(fit)
fit$coefficients
source("~/OSU_Thesis/Sample Data/Coding_Organization.R")
source("~/OSU_Thesis/Sample Data/Coding_Organization.R")
source("~/OSU_Thesis/Sample Data/Coding_Organization.R")
source("~/OSU_Thesis/Sample Data/Coding_Organization.R")
source("~/OSU_Thesis/Sample Data/Coding_Organization.R")
sd_noise<-5
nobs<-100    # number of observations
slope<-0.1
intercept<--1
sd_noise<-5
predictor<-seq(0,100,length.out=nobs)
noise<-rnorm(nobs,mean=0,sd=sd_noise)
response<-intercept+slope*predictor+noise
plot(response,predictor)
plot(predictor,response)
source("~/OSU_Thesis/Sample Data/Coding_Organization.R")
dat<-data.frame(predictor=predictor,
response=response)
source("~/OSU_Thesis/Sample Data/Coding_Organization.R")
fit<-glm(response~predictor, data = dat)
source("~/OSU_Thesis/Sample Data/Coding_Organization.R")
plot(predictor, response)
abline(fit)
source("~/OSU_Thesis/Sample Data/Coding_Organization.R")
predictor<-runif(n = nobs,0,100)
source("~/OSU_Thesis/Sample Data/Coding_Organization.R")
predictor<-runif(n = nobs,0,100)
dat<-data.frame(predictor=predictor,
response=response)
pred <- predict(fit, newdata = dat)
source("~/OSU_Thesis/Sample Data/Coding_Organization.R")
# Remove all variables
rm(list=ls())
## load all necessary packages
install.packages("devtools")
install_github("whoppitt/NBDA")
require(devtools)
## load all necessary packages
require(rmarkdown)  # “Knit” button (Ctrl+Shift+K) displays preview
install.packages("microbenchmark")
install.packages("parallel")
install.packages("doParallel")
install.packages("foreach")
# Upload packages
require(ggplot2)
require(microbenchmark)
require(parallel)
require(doParallel)
require(foreach)
knitr::opts_chunk$set(echo = TRUE)
set.seed(1) # for reproducibility
geom_growth_base <- function(N0 = 2,
T = 999,
lambda = 1.01,
sigma = 0.2){
Nvals <- vector('numeric') # initiate a place to put the values
Nvals[1] <- N0
for (t in 1:T){
Nvals[t+1] <- Nvals[t]*(lambda*exp(rnorm(1,0,sigma)))
}
return(Nvals)
}
# Run the simulation
out <- geom_growth_base()
# Plot the results
plot(0:999,
out,
xlab='Time',
ylab='Population size',
type='o')
```{r}
# Default number of time-points
start_time <- Sys.time()
out <- geom_growth_base()
end_time <- Sys.time()
end_time - start_time
# Repeat with greater number of time-points
start_time <- Sys.time()
out <- geom_growth_base(T = 9E5)
out <- geom_growth_base(T = 9E5)
end_time <- Sys.time()
end_time <- Sys.time()
end_time - start_time
# Note that the time won't be exactly the same each time (unless the seed is the same)
start_time <- Sys.time()
out <- geom_growth_base(T = 9E5)
out <- geom_growth_base(T = 9E5)
end_time <- Sys.time()
end_time - start_time
system.time(geom_growth_base(T=9E5))
comp <- microbenchmark(TS_009 = {geom_growth_base(T = 9)},
TS_099 = {geom_growth_base(T = 99)},
TS_999 = {geom_growth_base(T = 999)})
comp
autoplot(comp)
set.seed(1) # for reproducibility
geom_growth_preallocated <- function(N0 = 2,
T = 999,
lambda = 1.01,
sigma = 0.2){
Nvals <- vector('numeric', length = T+1) # here's the only change
Nvals[1] <- N0
for (i in 1:T){
Nvals[i+1] <- Nvals[i]*(lambda*exp(rnorm(1,0,sigma)))
}
return(Nvals)
}
# Compare the old and new simulation functions
comp <- microbenchmark(Old = {geom_growth_base(T = 9999)},
New = {geom_growth_preallocated(T = 9999)})
comp
\subsection{Progress bar}
\subsection{Progress bar}
data <- geom_growth_preallocated(T = 99999)
start_time <- Sys.time()
growth_rates <- vector('numeric', (length(data)-1))
for(i in 1:(length(data)-1)){
growth_rates[i] <- data[i+1] / data[i]
}
end_time <- Sys.time()
end_time-start_time
start_time <- Sys.time()
growth_rates <- data[-1] / data[-length(data)]
end_time <- Sys.time()
end_time-start_time
n <- 5 # number of time-series to create
# use replicate() to create n time-series, each in a different matrix column
dat_array <- replicate(n, geom_growth_preallocated(T = 9999))
colnames(dat_array) <- paste0('Site_', 1:n)
head(dat_array)
calc_growth_rates <- function(x){
gr <- x[-1] / x[-length(x)]
return(gr)
}
system.time({
apply(dat_array, 2, calc_growth_rates)
})
dat_list <- as.list(as.data.frame(dat_array))
system.time({
growth_rates <- lapply(dat_list, calc_growth_rates)
})
lapply(growth_rates, head) # look only at head of each list element
growth_rate_means <- lapply( lapply(dat_list, calc_growth_rates), mean)
growth_rate_means
unlist(growth_rate_means)
growth_rate_means <- lapply( lapply(dat_list, calc_growth_rates), mean)
growth_rate_means
unlist(growth_rate_means)
sapply( lapply(dat_list, calc_growth_rates), mean)
The function \texttt{mapply} is useful when you want to parameterize a function from multiple vectors.
# Generate a large amount of demonstration data
n <- 1E8
data_list <- list("A" = rnorm(n),
"B" = rnorm(n),
"C" = rnorm(n),
"D" = rnorm(n))
data_list <- list("A" = rnorm(n),
"B" = rnorm(n),
"C" = rnorm(n),
"D" = rnorm(n))
detectCores()
cores <- 2
cl <- makeCluster(cores) # Create cluster
registerDoParallel(cl) # Activate clusters
system.time({
means <- foreach(i = 1:length(data_list),
.combine = c) %dopar% {
# replace c with rbind to create a dataframe
mean(data_list[[i]])
}
})
detectcores()
detect.cores()
summaryRprof()
detectCores()
m.data<-read.csv("../data/m.data.csv")
setwd("C:/Users/bankh/My_Repos/habor-seal/results")
m.data<-read.csv("../data/m.data.csv")
unlink("Diagnostics_cache", recursive = TRUE)
install.packages('tinytex')
require(tinytex)
update.packages(ask = FALSE, checkBuilt = TRUE)
tinytex::tlmgr_update()
tinytex::reinstall_tinytex()
install.packages("tlmgr")
install.packages(c("bslib", "digest", "htmltools", "htmlwidgets", "nlme", "rmarkdown", "shiny", "xfun", "yaml"))
tinytex::install_tinytex()
update.packages(ask = FALSE, checkBuilt = TRUE)
tinytex::tlmgr_update()
install.packages("tlmgr")
update.packages(ask = FALSE, checkBuilt = TRUE)
tinytex::tlmgr_update()
require(tlmgr)
tinytex::reinstall_tinytex()
install.packages('tinytex')
install.packages("tinytex")
update.packages(ask = FALSE, checkBuilt = TRUE)
tinytex::tlmgr_update()
options(tinytex.verbose = TRUE)
knitr::opts_chunk$set(echo = TRUE)
# Retrieve data
m.data<-read.csv("../data/m.data.csv")
w.data<-read.csv("../data/w.data.csv")
# Check t-test assumptions
## Is noise normal?
hist(w.data$noise[w.data$location == 1], breaks = 15, main = "Location 1", xlab = "Noise Level (dB)")
hist(w.data$noise[w.data$location == 2], breaks = 15, main = "Location 2", xlab = "Noise Level (dB)")
# Set working directory here
setwd("C:/Users/bankh/My_Repos/habor-seal/data")
# Retrieve data
m.data<-read.csv("m.data.csv")
w.data<-read.csv("w.data.csv")
require(MASS) #for glm.nb()
# Combine location avg noise and total seals within dates
new.w.data<-read.csv("new.w.data.csv")
# Fix date
new.w.data$date<-as.Date(as.character(new.w.data$date),format = "%m/%d/%Y")
m.data$date<-as.Date(as.character(m.data$date),format = "%m/%d/%Y")
# Merge data
full.data<-merge(new.w.data,m.data,all = T)
full.data$time<-as.numeric(full.data$time)
full.data$month<-as.numeric(full.data$month)
# Check GLM
model1<- glm.nb(seals ~ 1, data = full.data)
model2<- glm.nb(seals ~ site*noise + month + tide + time, data = full.data)
model3<- glm.nb(seals ~ site*noise + month + time, data = full.data)
model4<- glm.nb(seals ~ site*noise + month, data = full.data)
summary(model3)
AICcmodavg::AICc(model1, model2, model3, model4)
AICcmodavg::AICc(model1)
## Find the AICc function
source("../code/Functions.R")
# Create list
models<-list(model1, model2, model3, model4)
## Calculate AICc with glm of models
AICc(models) # Looks like site*noise + month + time are the best predictors
summary(model3)
summary(model2)
summary(model3)
## Calculate AICc with glm of models
AICc(models) # Looks like site*noise + month + time are the best predictors
summary(model3)
## Check which one would fit better
m1<- glm.nb(seals ~ 1, data = full.data)
m3<- glm(seals ~ 1, data = full.data, family = "poisson")
pchisq(2 * (logLik(m1) - logLik(m3)), df = 1, lower.tail = FALSE)
summary(model3)
# Use model to predict the response variable
newdata <- data.frame(noise = mean(full.data$noise),
prog = factor(1:2, levels = 1:2,
labels = levels(full.data$site)))
levels(full.data$site)
full.data$site
unique(full.data$site)
# Use model to predict the response variable
newdata <- data.frame(noise = mean(full.data$noise),
prog = factor(1:2, levels = 1:2,
labels = unique(full.data$site)))
newdata$phat <- predict.glm(model3, newdata, type = "response")
newdata$phat <- predict(model3, newdata, type = "response")
model3
newdata$phat <- predict.glm(model3, newdata, type = "response")
newdata$phat <- predict.glm(model1, newdata, type = "response")
newdata
newdata$phat <- predict.glm(model4, newdata, type = "response")
m3<- glm.nb(seals ~ site + noise + month + time, data = full.data)
newdata$phat <- predict.glm(m3, newdata, type = "response")
m3<- glm.nb(seals ~ site + noise, data = full.data)
newdata$phat <- predict.glm(m3, newdata, type = "response")
full.data<- read.csv("full.data.csv")
# Use model to predict the response variable
newdata <- data.frame(noise = mean(full.data$noise),
prog = factor(1:2, levels = 1:2,
labels = unique(full.data$site)))
m3<- glm.nb(seals ~ site + noise, data = full.data)
newdata$phat <- predict.glm(m3, newdata, type = "response")
# Use model to predict the response variable
newdata <- data.frame(noise = mean(full.data$noise),
site = factor(1:2, levels = 1:2,
labels = unique(full.data$site)))
newdata$phat <- predict.glm(model3, newdata, type = "response")
m3<- glm.nb(seals ~ site * noise, data = full.data)
newdata$phat <- predict.glm(m3, newdata, type = "response")
newdata
# Use all range of noise to predict response
newdata2 <- data.frame(
noise = rep(seq(from = min(full.data$noise), to = max(full.data$noise), length.out = 70), 2),
site = factor(rep(1:2, each = 70), levels = 1:2, labels =
unique(full.data$site)))
newdata2 <- cbind(newdata2, predict.glm(m3, newdata2, type = "link", se.fit=TRUE))
newdata2 <- within(newdata2, {
SealsHauled <- exp(fit)
LL <- exp(fit - 1.96 * se.fit)
UL <- exp(fit + 1.96 * se.fit)
})
# Now plot these
ggplot(newdata2, aes(noise, seals)) +
geom_ribbon(aes(ymin = LL, ymax = UL, fill = site), alpha = .25) +
geom_line(aes(colour = site), size = 2) +
labs(x = "Noise Level (dB)", y = "Number of Seals Hauled-out")
# Load packages
require(ggplot2)
# Now plot these
ggplot(newdata2, aes(noise, seals)) +
geom_ribbon(aes(ymin = LL, ymax = UL, fill = site), alpha = .25) +
geom_line(aes(colour = site), size = 2) +
labs(x = "Noise Level (dB)", y = "Number of Seals Hauled-out")
# Now plot these
ggplot(newdata2, aes(noise, seals)) +
geom_ribbon(aes(ymin = LL, ymax = UL, fill = site), alpha = .25) +
geom_line(aes(colour = site), linewidth = 2) +
labs(x = "Noise Level (dB)", y = "Number of Seals Hauled-out")
newdata2
# Now plot these
ggplot(newdata2, aes(noise, seals)) +
geom_ribbon(aes(ymin = LL, ymax = UL, fill = site), alpha = .25) +
geom_line(aes(colour = site), linewidth = 2) +
labs(x = "Noise Level (dB)", y = "Number of Seals Hauled-out")
rlang::last_error()
# Use model to predict the response variable
newdata <- data.frame(noise = mean(full.data$noise),
month = mean(full.data$month),
time = mean(full.data$time),
site = factor(1:2, levels = 1:2,
labels = unique(full.data$site)))
newdata$phat <- predict.glm(m3, newdata, type = "response")
newdata$phat <- predict.glm(model3, newdata, type = "response")
newdata
newdata$phat <- predict.glm(model3, full.data, type = "response")
# Use model to predict the response variable
newdata <- data.frame(noise = mean(full.data$noise),
month = unique(full.data$month),
time = unique(full.data$time),
site = factor(1:2, levels = 1:2,
labels = unique(full.data$site)))
# Now plot these
ggplot(newdata2, aes(noise, seals)) +
geom_ribbon(aes(ymin = LL, ymax = UL, fill = site), alpha = .25) +
geom_line(aes(colour = site), linewidth = 2) +
labs(x = "Noise Level (dB)", y = "Number of Seals Hauled-out")
# Now plot these
ggplot(newdata2, aes(noise, seals)) +
geom_line(aes(colour = site), linewidth = 2) +
labs(x = "Noise Level (dB)", y = "Number of Seals Hauled-out")
ggplot(newdata2, aes(noise, seals))
# Use all range of noise to predict response
newdata2 <- data.frame(
noise = rep(seq(from = min(full.data$noise), to = max(full.data$noise), length.out = 70), 2),
site = factor(rep(1:2, each = 70), levels = 1:2, labels =
unique(full.data$site)))
newdata2 <- cbind(newdata2, predict.glm(m3, newdata2, type = "link", se.fit=TRUE))
newdata2 <- within(newdata2, {
SealsHauled <- exp(fit)
LL <- exp(fit - 1.96 * se.fit)
UL <- exp(fit + 1.96 * se.fit)
})
ggplot(newdata2, aes(noise, seals))
# Plot on top of raw data
effect_plot(model3, pred = noise)
# Load packages
require(ggplot2)
# Plot on top of raw data
effect_plot(model3, pred = noise)
effect_plot(l_mod, pred = week, interval = TRUE, y.label = "% testing positive")
update.packages("ggplot2")
effect_plot(l_mod, pred = week, interval = TRUE, y.label = "% testing positive")
install.packages("jtools")
require(jtools)
effect_plot(l_mod, pred = week, interval = TRUE, y.label = "% testing positive")
# Plot on top of raw data
effect_plot(model3, pred = noise)
# Plot on top of raw data
effect_plot(model3, pred = noise, interval = TRUE, partial.residuals = TRUE,
jitter = c(0.1, 0))
# Plot on top of raw data
effect_plot(model3, pred = noise, interval = TRUE, partial.residuals = TRUE,
jitter = c(0.1, 0), xlab("Average Noise Level (dB)"))
# Plot on top of raw data
effect_plot(model3, pred = noise, interval = TRUE, partial.residuals = TRUE,
jitter = c(0.1, 0), x.label = "Average Noise Level (dB)",
y.label = "Number of Seals Hauled-out")
# Plot on top of raw data
effect_plot(full.data, pred = noise, interval = TRUE, partial.residuals = TRUE,
jitter = c(0.1, 0), x.label = "Average Noise Level (dB)",
y.label = "Number of Seals Hauled-out")
# Plot on top of raw data
effect_plot(m3, pred = noise, interval = TRUE, partial.residuals = TRUE,
jitter = c(0.1, 0), x.label = "Average Noise Level (dB)",
y.label = "Number of Seals Hauled-out")
# Plot on top of raw data
effect_plot(model3, pred = noise, interval = TRUE, partial.residuals = TRUE,
jitter = c(0.1, 0), x.label = "Average Noise Level (dB)",
y.label = "Number of Seals Hauled-out")
effect_plot(model3, pred = noise)
effect_plot(model3, pred = noise, interval = TRUE)
effect_plot(model3, pred = noise, interval = TRUE,plot.points = T)
effect_plot(model3, pred = noise, interval = TRUE,partial.residuals = TRUE)
library(sjPlot)
install.packages("sjPlot")
library(sjPlot)
sjp.int(model3, swap.pred = T)
sjp.int(model3, swap.pred = T)
x.order <- c('Waterfront', 'Marina')
ggplot(full.data, aes(x = site, y = noise)) +
geom_violin(fill = "grey")+ geom_boxplot(width = .2)+xlab("Site")+ylab("Average Noise Level (dB)")+scale_x_discrete(limit = c("waterfront", "marina"),labels = c("Waterfront","Marina"))+theme(panel.background = element_blank())
hist(w.data$noise[full.data$site == "waterfront"], breaks = 15, main = "Waterfront", xlab = "Noise Level (dB)")
hist(w.data$noise[full.data$site == "waterfront"], breaks = 15, main = "Waterfront", xlab = "Noise Level (dB)")
hist(full.data$noise[full.data$site == "waterfront"], breaks = 15, main = "Waterfront", xlab = "Noise Level (dB)")
knitr::opts_chunk$set(echo = TRUE)
# waterfront
hist(full.data$noise[full.data$site == "waterfront"], breaks = 15, main = "Waterfront", xlab = "Noise Level (dB)")
# marina
hist(full.data$noise[full.data$site == "marina"], breaks = 15, main = "Marina", xlab = "Noise Level (dB)")
# waterfront
var(full.data$noise[full.data$site == "waterfront"])
# marina
var(full.data$noise[full.data$site == "marina"])
#U-test
wilcox.test(noise ~ site, data = full.data,
exact = FALSE)
res<-wilcox.test(full.data$noise[full.data$site == "waterfront"], full.data$noise[full.data$site == "marina"])
res$p.value
require(performance)
check_zeroinflation(model3)
check_overdispersion(model3)
dispersiontest(model3,trafo=1)
check_overdispersion(model3)
